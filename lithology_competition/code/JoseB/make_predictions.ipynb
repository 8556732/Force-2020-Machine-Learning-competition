{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pickle\n",
    "import ipywidgets as widgets\n",
    "# from utils import *\n",
    "pd.set_option('display.max_columns', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map of lithology codes to description\n",
    "lithology_keys = {30000: 'Sandstone',\n",
    "                 65030: 'Sandstone/Shale',\n",
    "                 65000: 'Shale',\n",
    "                 80000: 'Marl',\n",
    "                 74000: 'Dolomite',\n",
    "                 70000: 'Limestone',\n",
    "                 70032: 'Chalk',\n",
    "                 88000: 'Halite',\n",
    "                 86000: 'Anhydrite',\n",
    "                 99000: 'Tuff',\n",
    "                 90000: 'Coal',\n",
    "                 93000: 'Basement'}\n",
    "    \n",
    "# map of lithology codes to integer label for ML\n",
    "lithology_numbers = {30000: 0,\n",
    "                     65030: 1,\n",
    "                     65000: 2,\n",
    "                     80000: 3,\n",
    "                     74000: 4,\n",
    "                     70000: 5,\n",
    "                     70032: 6,\n",
    "                     88000: 7,\n",
    "                     86000: 8,\n",
    "                     99000: 9,\n",
    "                     90000: 10,\n",
    "                     93000: 11}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, models_file,\n",
    "                 modelF_file,\n",
    "                 modelDTC_file,\n",
    "                 dictF_file, \n",
    "                 median_trn_file,\n",
    "                 feats_name_file):\n",
    "        # Load pre-trained model from file\n",
    "        self.models = pickle.load(open(models_file, 'rb'))\n",
    "        # Load dict\n",
    "        self.dictF = pickle.load(open(dictF_file, 'rb'))\n",
    "        #load median values statistics\n",
    "        self.median_trn = pickle.load(open(median_trn_file, 'rb'))\n",
    "        # load models for filling missing data\n",
    "        self.modelF = pickle.load(open(modelF_file, 'rb'))\n",
    "        self.modelDTC = pickle.load(open(modelDTC_file, 'rb'))\n",
    "        self.feats_name =  pickle.load(open(feats_name_file, 'rb'))\n",
    "        \n",
    "    def _preprocess(self, features):\n",
    "        # Method to be run before inference. Contains things like\n",
    "        # stripping unwanted columns, replacing NaNs\n",
    "        features = features[['WELL','DEPTH_MD','X_LOC','Y_LOC','GROUP',\n",
    "                            'FORMATION','CALI','RSHA','RMED','RDEP','RHOB','GR',\n",
    "                            'NPHI', 'PEF', 'DTC', 'SP', 'BS', 'DRHO']]\n",
    "        features = self.fillGROUP(features)\n",
    "        features = self.fillRDEP(features)\n",
    "        features = self.fillXYLOC(features)\n",
    "        features = self.fillFORMATION(features)\n",
    "        features = self.fillDTC(features)\n",
    "        # filling remaining missing data using train statictis\n",
    "        features.fillna(self.median_trn, inplace=True)\n",
    "        features.drop(columns=['WELL','DTC_media', 'GROUP','GcatCodes', 'FcatCodes'], inplace=True)        \n",
    "        features = pd.get_dummies(features, columns=['FORMATION'], drop_first=True)\n",
    "        features = self.fillFeatures(features)\n",
    "        return features\n",
    "        \n",
    "    def predict(self, features):\n",
    "        # This function should be able to take in features in their\n",
    "        # raw, unprocessed form as read from the file test.csv and\n",
    "        # return predictions as an array integers of the same length\n",
    "        features = self._preprocess(features)\n",
    "        preds = np.zeros((len(features), 12))\n",
    "        for clf in self.models:\n",
    "            preds += clf.predict_proba(features)\n",
    "        return np.argmax(preds, axis=-1)\n",
    "    \n",
    "    def fillFeatures(self, features):\n",
    "        # create a container with same columns of training data.\n",
    "        test_features = pd.DataFrame(columns=self.feats_name, data=np.zeros((len(features), len(self.feats_name))))\n",
    "        features = test_features + features\n",
    "        features.fillna(0, inplace=True)\n",
    "        features = features[self.feats_name]\n",
    "#         print(features.keys())\n",
    "        return features\n",
    "    \n",
    "    def fillGROUP(self, features):\n",
    "        df_ = features.copy()\n",
    "        for well in df_.WELL[df_.GROUP.isna()].unique():\n",
    "            df_.GROUP.loc[df_.WELL==well] = df_.GROUP.loc[df_.WELL==well].fillna(method='bfill')\n",
    "        return df_\n",
    "    \n",
    "    def fillRDEP(self, features):\n",
    "        df_ = features.copy()\n",
    "        for well in df_.WELL[df_.RDEP.isna()].unique():\n",
    "            data = df_.RDEP.loc[df_.WELL==well]\n",
    "            df_.RDEP.loc[df_.WELL==well] = data.fillna(data.median())\n",
    "        return df_\n",
    "    \n",
    "    def fillXYLOC(self, features):\n",
    "        df_ = features.copy()\n",
    "        for well in df_.WELL.unique():\n",
    "            X_values = df_.X_LOC.loc[df_.WELL==well]\n",
    "            Y_values = df_.Y_LOC.loc[df_.WELL==well]\n",
    "            if X_values.isna().sum() > 0:\n",
    "                X_values = X_values.fillna(method='bfill')\n",
    "                df_.X_LOC.loc[df_.WELL==well] = X_values.fillna(method='ffill')\n",
    "            if Y_values.isna().sum() > 0:\n",
    "                Y_values = Y_values.fillna(method='bfill')\n",
    "                df_.Y_LOC.loc[df_.WELL==well] = Y_values.fillna(method='ffill')\n",
    "        return df_\n",
    "    \n",
    "    def fillFORMATION(self, features):\n",
    "        df_ = features.copy()\n",
    "        dfF = df_[['WELL','DEPTH_MD','GROUP', 'GR', 'RDEP', 'FORMATION']]\n",
    "        dfF.GROUP = dfF.GROUP.astype('category')\n",
    "        dfF['GcatCodes'] = dfF.GROUP.cat.codes\n",
    "\n",
    "        wells = dfF.WELL.unique()\n",
    "        window = 100\n",
    "\n",
    "        df_temp = []\n",
    "        for well in wells:\n",
    "            DatabyWell = dfF.loc[dfF.WELL==well].sort_values(by='DEPTH_MD')\n",
    "            DatabyWell['GR_median']= DatabyWell['GR'].rolling(window).median()\n",
    "            DatabyWell['RDEP_median']= DatabyWell['RDEP'].rolling(window).median()\n",
    "            DatabyWell['GR_std'] = DatabyWell['GR'].rolling(window).std()    \n",
    "            DatabyWell['RDEP_std'] = DatabyWell['RDEP'].rolling(window).std()\n",
    "\n",
    "            DatabyWell.GR_median = DatabyWell.GR_median.fillna(method='bfill')\n",
    "            DatabyWell.RDEP_median = DatabyWell.RDEP_median.fillna(method='bfill')\n",
    "\n",
    "            DatabyWell.GR_std = DatabyWell.GR_std.fillna(method='bfill')    \n",
    "            DatabyWell.RDEP_std = DatabyWell.RDEP_std.fillna(method='bfill')\n",
    "\n",
    "            df_temp.append(DatabyWell)\n",
    "\n",
    "        dfF = pd.concat(df_temp)\n",
    "        dfF = dfF.loc[dfF.FORMATION.isna()]\n",
    "        X_Data = dfF[['DEPTH_MD','GR','GR_median','GR_std','RDEP','RDEP_median','RDEP_std','GcatCodes']]\n",
    "\n",
    "        pred_F = self.modelF.predict(X_Data)\n",
    "\n",
    "        dfF.FORMATION = dfF.FORMATION.astype('str')\n",
    "        dfF.FORMATION.loc[dfF.index] = [self.dictF[pred_F[i]] for i in range(len(pred_F))]\n",
    "        df_.FORMATION.loc[dfF.index] = dfF.FORMATION\n",
    "        return df_\n",
    "    \n",
    "    def fillDTC(self, features, window_dtc=50):\n",
    "        df_ = features.copy()\n",
    "        df_.GROUP = df_.GROUP.astype('category')\n",
    "        df_.FORMATION = df_.FORMATION.astype('category')\n",
    "        df_['GcatCodes'] = df_.GROUP.cat.codes\n",
    "        df_['FcatCodes'] = df_.FORMATION.cat.codes\n",
    "        df_['DTC_media'] = 0\n",
    "        for well in df_.WELL.unique():\n",
    "            df_.DTC_media.loc[df_.WELL==well] = self.modelDTC.predict(df_[df_.WELL==well][['DEPTH_MD','GR','GcatCodes','FcatCodes']])\n",
    "            df_.DTC_media.loc[df_.WELL==well] = df_.DTC_media.loc[df_.WELL==well].rolling(window_dtc).median()\n",
    "            df_.DTC_media.loc[df_.WELL==well] = df_.DTC_media.loc[df_.WELL==well].fillna(method='bfill')\n",
    "            df_.DTC.loc[df_.DTC.isna()] = df_.DTC_media.loc[df_.DTC.isna()]        \n",
    "        return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(models_file='models.pkl', \n",
    "              modelF_file='model_F.pkl',\n",
    "              modelDTC_file='model_DTC.pkl',\n",
    "              dictF_file='dictF.pkl' ,\n",
    "              median_trn_file='train_median.pkl',\n",
    "              feats_name_file='feat_Columns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_test_features = pd.read_csv('test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:189: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "test_prediction = model.predict(open_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_lithology = {y:x for x,y in lithology_numbers.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction_for_submission = np.vectorize(category_to_lithology.get)(test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = pd.read_csv('/scratch/parceirosbr/bigoilict/share/GeoFacies/Maykol/Force/notebooks/sub41.csv')\n",
    "# target = pd.read_csv('/scratch/parceirosbr/bigoilict/share/GeoFacies/Force/best_8features.csv')\n",
    "# best_8features_cor.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9502726887254543"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(target.values.ravel()==test_prediction_for_submission).sum()/len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('test_predictions_jb.csv', test_prediction_for_submission, header='lithology', comments='', fmt='%i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
