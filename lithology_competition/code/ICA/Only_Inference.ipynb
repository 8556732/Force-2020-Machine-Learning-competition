{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.signal import medfilt\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliar Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize_Data_by_Well(dataFrame,col='GR'):\n",
    "    wells = dataFrame['WELL'].unique()\n",
    "    values = []\n",
    "    for well in wells:\n",
    "        min_value = dataFrame[dataFrame['WELL'] == well][col].min()\n",
    "        max_value = dataFrame[dataFrame['WELL'] == well][col].max()\n",
    "        col_normalized = (dataFrame[dataFrame['WELL'] == well][col].values-min_value)/(max_value-min_value)\n",
    "        values = values + list(col_normalized)\n",
    "    return values\n",
    "\n",
    "def Delta_Feature(dataFrame,col='GR',inverted=False):\n",
    "    wells = dataFrame['WELL'].unique()\n",
    "    values = []\n",
    "    for well in wells:\n",
    "        col_values = dataFrame[dataFrame['WELL'] == well][col].values\n",
    "        col_values_ = np.array([col_values[0]]+list(col_values[:-1]))\n",
    "        delta_col_values = col_values-col_values_\n",
    "        if inverted:\n",
    "            delta_col_values=-delta_col_values\n",
    "        values = values + list(delta_col_values)\n",
    "    return values\n",
    "\n",
    "def Add_New_Features(dataFrame):\n",
    "    data = dataFrame['RHOB'].values  \n",
    "    data = ((154.497/data) - 57.261)\n",
    "    dataFrame['Carbon_Index'] = data\n",
    "    dataFrame['Normalized_RHOB'] = Normalize_Data_by_Well(dataFrame,col='RHOB')\n",
    "    dataFrame['Normalized_GR'] = Normalize_Data_by_Well(dataFrame,col='GR')    \n",
    "    dataFrame['Delta_DTC'] = Delta_Feature(dataFrame,col='DTC',inverted=True)\n",
    "    dataFrame['Delta_RHOB'] = Delta_Feature(dataFrame,col='RHOB',inverted=True)    \n",
    "    dataFrame['Delta_GR'] = Delta_Feature(dataFrame,col='GR',inverted=True)\n",
    "    dataFrame['Delta_DEPTH_MD'] = Delta_Feature(dataFrame,col='DEPTH_MD')\n",
    "    dataFrame['Delta_Carbon_Index'] = Delta_Feature(dataFrame,col='Carbon_Index')\n",
    "    \n",
    "    return dataFrame\n",
    "\n",
    "def Fill_Data(dataFrame,fill_formation,fill_BS,fill_with_median):\n",
    "    dataFrame.FORMATION = dataFrame.FORMATION.fillna(fill_formation)\n",
    "    dataFrame.BS = dataFrame.BS.fillna(fill_BS)\n",
    "    dataFrame.fillna(fill_with_median, inplace=True)\n",
    "    dataFrame = pd.get_dummies(dataFrame, columns=['FORMATION'], drop_first=True)\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_numbers = {30000: 0,\n",
    "                 65030: 1,\n",
    "                 65000: 2,\n",
    "                 80000: 3,\n",
    "                 74000: 4,\n",
    "                 70000: 5,\n",
    "                 70032: 6,\n",
    "                 88000: 7,\n",
    "                 86000: 8,\n",
    "                 99000: 9,\n",
    "                 90000: 10,\n",
    "                 93000: 11}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, model_files, fill_information='fill_information.pkl'):\n",
    "        # Load pre-trained models from file\n",
    "        self.model_files=model_files\n",
    "        \n",
    "        #self.model=[]\n",
    "        #for i,file in enumerate(model_files):\n",
    "        #    self.model.append(pk.load(open(file, 'rb')))\n",
    "        \n",
    "        # Load a \"filles-information\" from file\n",
    "        self.fill_information = pk.load(open(fill_information, 'rb'))\n",
    "        \n",
    "    def _preprocess(self, features):\n",
    "        # Method to be run before inference.\n",
    "        features = Add_New_Features(features)\n",
    "        features = Fill_Data(features,self.fill_information[0],self.fill_information[1],self.fill_information[2])\n",
    "        complete_features = pd.DataFrame(columns=self.fill_information[-1], \n",
    "                                   data=np.zeros((features.shape[0], len(self.fill_information[-1]))))\n",
    "        for col in complete_features.columns:\n",
    "            if col in features.columns:\n",
    "                complete_features[col] = features[col]\n",
    "        \n",
    "        return complete_features\n",
    "    def corrections(self,features):\n",
    "        for well in features['WELL'].unique():\n",
    "            values_by_facies = features[features['WELL']==well]['Prediction'].value_counts()\n",
    "            values_by_facies = values_by_facies[values_by_facies < 20].index\n",
    "            for value in values_by_facies :\n",
    "                v = features[(features['WELL']==well)]['Prediction'].values\n",
    "                v[v==value] = features[features['WELL']==well]['Prediction'].value_counts().index[0].astype('int64')\n",
    "                features.loc[features['WELL']==well,'Prediction'] = v\n",
    "            \n",
    "            features.loc[features['WELL']==well,'Prediction'] = medfilt(features[features['WELL']==well]['Prediction'].values,\n",
    "                                                                        kernel_size=3)\n",
    "        return features['Prediction'].values\n",
    "    def predict(self, features):\n",
    "        # This function should be able to take in features in their\n",
    "        # raw, unprocessed form as read from the file test.csv and\n",
    "        # return predictions as an array integers of the same length        \n",
    "        features_base = features.copy()\n",
    "        X = self._preprocess(features)\n",
    "        y_t = np.zeros((X.shape[0], 12))\n",
    "        for model_file in self.model_files:\n",
    "            model = pk.load(open(model_file, 'rb'))        \n",
    "            y_t += model.predict_proba(X)\n",
    "            del model # delete object to clear memory\n",
    "        predictions = np.argmax(y_t, axis=-1)\n",
    "        category_to_lithology = {y:x for x,y in lithology_numbers.items()}\n",
    "        test_prediction_for_submission = np.vectorize(category_to_lithology.get)(predictions)\n",
    "\n",
    "        features_base['Prediction'] = test_prediction_for_submission        \n",
    "        #return predictions       \n",
    "        return self.corrections(features_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load TestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_test_features = pd.read_csv('test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(['trained_model_1.pkl','trained_model_2.pkl',\n",
    "               'trained_model_3.pkl','trained_model_4.pkl',\n",
    "               'trained_model_5.pkl'], 'fill_information.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = model.predict(open_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('test_predictions.csv', test_prediction, header='lithology', comments='', fmt='%i')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
