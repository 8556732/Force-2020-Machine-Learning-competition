{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import pickle\n",
    "from utility import data_modify, impute_nan, combine_features, augment_features\n",
    "# suppress the chained indexing warnings entirely\n",
    "pd.set_option('mode.chained_assignment',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology_numbers = {30000: 0,\n",
    "                     65030: 1,\n",
    "                     65000: 2,\n",
    "                     80000: 3,\n",
    "                     74000: 4,\n",
    "                     70000: 5,\n",
    "                     70032: 6,\n",
    "                     88000: 7,\n",
    "                     86000: 8,\n",
    "                     99000: 9,\n",
    "                     90000: 10,\n",
    "                     93000: 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, model_file, scaler_file):\n",
    "        # Load pre-trained model from file\n",
    "        self.model = pickle.load(open(model_file, 'rb'))\n",
    "        # Load a \"pre-trained\" scaler from file\n",
    "        self.scaler = pickle.load(open(scaler_file, 'rb'))\n",
    "        \n",
    "    def _preprocess(self, features):\n",
    "        # Method to be run before inference. Contains things like\n",
    "        # stripping unwanted columns, replacing NaNs, and scaling \n",
    "        # or normalizing data\n",
    "        feats=features[['DEPTH_MD', 'X_LOC', 'Y_LOC', 'Z_LOC', 'CALI', 'GR', 'RSHA', 'RMED', 'RDEP', 'RHOB', \n",
    "                       'NPHI', 'PEF', 'DTC', 'DTS', 'SP', 'ROP', 'BS']]\n",
    "        feats=data_modify(feats)\n",
    "        feats=feats.fillna(0)\n",
    "        group, formation = impute_nan(feats, features['GROUP'], features['FORMATION'])\n",
    "        feats=combine_features(feats, formation, group)\n",
    "        feats=feats.drop(['DTS', 'ROP', 'BS'], axis=1)\n",
    "        feats_aug = augment_features(feats, features['WELL'], features['DEPTH_MD'])\n",
    "\n",
    "        return self.scaler.transform(feats_aug)\n",
    "    \n",
    "    def predict(self, features):\n",
    "        # This function should be able to take in features in their\n",
    "        # raw, unprocessed form as read from the file test.csv and\n",
    "        # return predictions as an array integers of the same length\n",
    "        X = self._preprocess(features)\n",
    "        return self.model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model('model.pkl', 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_test = pd.read_csv('D:/.jupyter/Machine_Predicted_Lithology/test.csv', sep=';', memory_map=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = model.predict(open_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., ..., 1., 0., 1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_lithology = {y:x for x,y in lithology_numbers.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction_for_submission = np.vectorize(category_to_lithology.get)(test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([65000, 65000, 65000, ..., 65030, 30000, 65030])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction_for_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('test_predictions.csv', test_prediction_for_submission, header='lithology', comments='', fmt='%i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
